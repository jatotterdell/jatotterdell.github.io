<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>logistic regression on James Totterdell</title>
    <link>https://jatotterdell.github.io/categories/logistic-regression/</link>
    <description>Recent content in logistic regression on James Totterdell</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Tue, 04 Jun 2019 00:00:00 +0000</lastBuildDate><atom:link href="https://jatotterdell.github.io/categories/logistic-regression/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Prior Coding Effects</title>
      <link>https://jatotterdell.github.io/post/2019/06/04/prior-coding-effects/</link>
      <pubDate>Tue, 04 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://jatotterdell.github.io/post/2019/06/04/prior-coding-effects/</guid>
      <description>To a certain extent, coding matrices in frequentist inference are arbitrary. We might choose a certain coding to make inference for hypotheses straightforward in the context of the model parameterisation. For example (see vignette Venables 2018), assuming \(p\) cell means of interest \(\mu\), we could begin with the incidence matrix \[ X = \begin{pmatrix} \mathbf 1_{n_1} &amp;amp; 0 &amp;amp; \cdots &amp;amp; 0 \\ 0 &amp;amp; \mathbf 1_{n_2} &amp;amp; \cdots &amp;amp; 0 \\ \vdots &amp;amp; \vdots &amp;amp; \ddots &amp;amp; \vdots \\ 0 &amp;amp; 0 &amp;amp; \cdots &amp;amp; \mathbf 1_{n_p} \end{pmatrix} \] with linear predictor \(\eta = X\mu\).</description>
    </item>
    
    <item>
      <title>Logistic Regression Variational Approximation - I</title>
      <link>https://jatotterdell.github.io/post/2019/05/25/logistic-regression-variational-approximation/</link>
      <pubDate>Sat, 25 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://jatotterdell.github.io/post/2019/05/25/logistic-regression-variational-approximation/</guid>
      <description>Background Approximation Bounds Bohning Jaakkola-Jordan Saul-Jordan  Examples Example 1 Example 2 Example 3 (divergence)  Summary Useful Identities References   Background Previously, I had worked through derivations of variational approximations for a linear regression model and proportional hazards exponential model with right-censoring. This post works through approximations for logistic regression models.
Some general references on variational approximations for logistic regression are Murphy (2012), Nolan and Wand (2017), and Wand (2017).</description>
    </item>
    
  </channel>
</rss>
