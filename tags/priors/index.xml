<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>priors on James Totterdell</title>
    <link>https://jatotterdell.github.io/tags/priors/</link>
    <description>Recent content in priors on James Totterdell</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Mon, 02 Sep 2019 00:00:00 +0000</lastBuildDate><atom:link href="https://jatotterdell.github.io/tags/priors/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Bayesian ANOVA Parameterisation</title>
      <link>https://jatotterdell.github.io/post/2019/09/02/bayesian-anova-parameterisation/</link>
      <pubDate>Mon, 02 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://jatotterdell.github.io/post/2019/09/02/bayesian-anova-parameterisation/</guid>
      <description>Background ANOVA methods are essentially about “batching” related model parameters to aid interpretability of the results (e.g. Gelman 2005). This batching is usually achieved by enforcing some kind of constraint on the parameters within the model. In classical inference, such constraints can be enforced in a number of ways and, to some extent, immaterially affect the inference due to the arbitrariness of the design matrix. However, in Bayesian inference, parameterisation determines our priors which influence our inferences.</description>
    </item>
    
    <item>
      <title>Prior Coding Effects</title>
      <link>https://jatotterdell.github.io/post/2019/06/04/prior-coding-effects/</link>
      <pubDate>Tue, 04 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://jatotterdell.github.io/post/2019/06/04/prior-coding-effects/</guid>
      <description>To a certain extent, coding matrices in frequentist inference are arbitrary. We might choose a certain coding to make inference for hypotheses straightforward in the context of the model parameterisation. For example (see vignette Venables 2018), assuming \(p\) cell means of interest \(\mu\), we could begin with the incidence matrix \[ X = \begin{pmatrix} \mathbf 1_{n_1} &amp;amp; 0 &amp;amp; \cdots &amp;amp; 0 \\ 0 &amp;amp; \mathbf 1_{n_2} &amp;amp; \cdots &amp;amp; 0 \\ \vdots &amp;amp; \vdots &amp;amp; \ddots &amp;amp; \vdots \\ 0 &amp;amp; 0 &amp;amp; \cdots &amp;amp; \mathbf 1_{n_p} \end{pmatrix} \] with linear predictor \(\eta = X\mu\).</description>
    </item>
    
  </channel>
</rss>
