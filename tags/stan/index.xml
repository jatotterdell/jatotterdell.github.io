<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Stan on James Totterdell</title>
    <link>https://jatotterdell.github.io/tags/stan/</link>
    <description>Recent content in Stan on James Totterdell</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Mon, 02 Sep 2019 00:00:00 +0000</lastBuildDate><atom:link href="https://jatotterdell.github.io/tags/stan/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Bayesian ANOVA Parameterisation</title>
      <link>https://jatotterdell.github.io/post/2019/09/02/bayesian-anova-parameterisation/</link>
      <pubDate>Mon, 02 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://jatotterdell.github.io/post/2019/09/02/bayesian-anova-parameterisation/</guid>
      <description>Background ANOVA methods are essentially about “batching” related model parameters to aid interpretability of the results (e.g. Gelman 2005). This batching is usually achieved by enforcing some kind of constraint on the parameters within the model. In classical inference, such constraints can be enforced in a number of ways and, to some extent, immaterially affect the inference due to the arbitrariness of the design matrix. However, in Bayesian inference, parameterisation determines our priors which influence our inferences.</description>
    </item>
    
    <item>
      <title>Ordinal Models Likert Scale Data</title>
      <link>https://jatotterdell.github.io/post/2019/04/25/ordinal-models-likert-scale-data/</link>
      <pubDate>Thu, 25 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://jatotterdell.github.io/post/2019/04/25/ordinal-models-likert-scale-data/</guid>
      <description>Background I was recently tasked with providing support to a study where the primary outcome was an eight-item, seven-point Likert scale. The proposal was to use a t-test to undertake the analysis. Being unfamiliar with the analysis of Likert scale responses I decided to do a bit of research into what was standard practice.
There appears to be disagreement about whether the appropriate analysis should be based on parametric or non-parametric methods (Sullivan and Artino Jr 2013).</description>
    </item>
    
    <item>
      <title>Semiparametric baseline hazard using monotone splines</title>
      <link>https://jatotterdell.github.io/post/2019/04/11/semiparametric-baseline-hazard-using-monotone-splines/</link>
      <pubDate>Thu, 11 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://jatotterdell.github.io/post/2019/04/11/semiparametric-baseline-hazard-using-monotone-splines/</guid>
      <description>Background I had been following a conversation on the Stan discourse about implementing flexible survival models in Stan. A common thread of the discussions was the use of monotone splines (M-splines) and their corresponding integrated splines (I-splines) as a semi-parametric model for the baseline cumulative hazard (or baseline log-cumulative hazard).
I have previously encountered the paper by (Ramsay and others 1988) whilst reading about spline extensions to the self-controlled case series (SCCS) method, but did not have much time to get into the details.</description>
    </item>
    
  </channel>
</rss>
